{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data shape: (843934, 9)\n",
      "First 3 rows:\n",
      "  symbol                 timestamp    open    high     low   close  volume  \\\n",
      "0   AAPL 2024-08-26 08:00:00+00:00  226.25  226.41  226.25  226.41  1965.0   \n",
      "1   AMZN 2024-08-26 08:00:00+00:00  177.00  177.60  177.00  177.30  6356.0   \n",
      "2   AVGO 2024-08-26 08:00:00+00:00  165.75  165.75  165.75  165.75   359.0   \n",
      "\n",
      "   trade_count        vwap  \n",
      "0        219.0  226.365909  \n",
      "1        150.0  177.363163  \n",
      "2         13.0  165.750000  \n",
      "Total missing values: 0\n",
      "Duplicates (symbol, timestamp): 0\n",
      "\n",
      "Training size: 590725\n",
      "Testing size: 253209\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# 1. Data Loading, Validation, and Train/Test Splitting\n",
    "# ---------------------------------------------------\n",
    "\n",
    "data_path = r'C:\\Zeel\\UChicago\\Winter\\Real Time Intelligence Systems\\Project Phase 1\\data\\historical_stock_data_5min_6months.csv'\n",
    "df = pd.read_csv(data_path, parse_dates=['timestamp'])\n",
    "\n",
    "print(\"Raw data shape:\", df.shape)\n",
    "print(\"First 3 rows:\")\n",
    "print(df.head(3))\n",
    "print(\"Total missing values:\", df.isnull().sum().sum())\n",
    "print(\"Duplicates (symbol, timestamp):\", df.duplicated(subset=['symbol', 'timestamp']).sum())\n",
    "\n",
    "# Split by symbol into training (70%) and testing (30%) sets\n",
    "train_data_list = []\n",
    "test_data_list = []\n",
    "for symbol, group in df.groupby(\"symbol\"):\n",
    "    group = group.sort_values(\"timestamp\")\n",
    "    split_idx = int(0.7 * len(group))\n",
    "    train_data_list.append(group.iloc[:split_idx])\n",
    "    test_data_list.append(group.iloc[split_idx:])\n",
    "    \n",
    "train_data = pd.concat(train_data_list).reset_index(drop=True)\n",
    "test_data = pd.concat(test_data_list).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nTraining size:\", len(train_data))\n",
    "print(\"Testing size:\", len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zeelp\\AppData\\Local\\Temp\\ipykernel_7604\\1779529022.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[\"CCI\"] = df.groupby(\"symbol\", group_keys=False).apply(calculate_cci)\n",
      "C:\\Users\\zeelp\\AppData\\Local\\Temp\\ipykernel_7604\\1779529022.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[\"CCI\"] = df.groupby(\"symbol\", group_keys=False).apply(calculate_cci)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# 2. Compute Technical Indicators\n",
    "# ---------------------------------------------------\n",
    "def calculate_indicators(df):\n",
    "    # Typical Price for CCI\n",
    "    df[\"typical_price\"] = (df[\"high\"] + df[\"low\"] + df[\"close\"]) / 3\n",
    "\n",
    "    # 200-period EMA on close\n",
    "    df[\"200_EMA\"] = df.groupby(\"symbol\")[\"close\"].transform(\n",
    "        lambda x: x.ewm(span=200, min_periods=200).mean()\n",
    "    )\n",
    "    \n",
    "    # VWAP Signal with volume filter (assuming 'vwap' column exists in your data)\n",
    "    df[\"volume_20_avg\"] = df.groupby(\"symbol\")[\"volume\"].transform(lambda x: x.rolling(20).mean())\n",
    "    df[\"vwap_signal\"] = np.where(\n",
    "        (df[\"close\"] > df[\"vwap\"]) & (df[\"volume\"] > 0.8 * df[\"volume_20_avg\"]), 1,\n",
    "        np.where((df[\"close\"] < df[\"vwap\"]) & (df[\"volume\"] > 0.8 * df[\"volume_20_avg\"]), -1, 0)\n",
    "    )\n",
    "    \n",
    "    # CCI Calculation\n",
    "    def calculate_cci(group):\n",
    "        tp = group[\"typical_price\"]\n",
    "        sma = tp.rolling(20).mean()\n",
    "        mad_vals = tp.rolling(20).apply(lambda x: np.abs(x - x.mean()).mean(), raw=True)\n",
    "        cci = (tp - sma) / (0.015 * mad_vals)\n",
    "        return cci\n",
    "\n",
    "    df[\"CCI\"] = df.groupby(\"symbol\", group_keys=False).apply(calculate_cci)\n",
    "    df[\"cci_signal\"] = np.where(df[\"CCI\"] > 150, 1, np.where(df[\"CCI\"] < -150, -1, 0))\n",
    "\n",
    "    # EMA Crossover: 9-period and 26-period EMAs\n",
    "    df[\"9_EMA\"] = df.groupby(\"symbol\")[\"close\"].transform(lambda x: x.ewm(span=9, min_periods=9).mean())\n",
    "    df[\"26_EMA\"] = df.groupby(\"symbol\")[\"close\"].transform(lambda x: x.ewm(span=26, min_periods=26).mean())\n",
    "    df[\"ema_crossover\"] = np.where(df[\"9_EMA\"] > df[\"26_EMA\"], 1, -1)\n",
    "    \n",
    "    # 200_EMA signal (if close > 200_EMA then 1, else -1)\n",
    "    df['200_EMA_signal'] = np.where(df['close'] > df['200_EMA'], 1, -1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_data = calculate_indicators(train_data)\n",
    "test_data = calculate_indicators(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# 3. Create a Target Variable and Feature Set for ML\n",
    "# ---------------------------------------------------\n",
    "# Define target: 1 if next candle's close > current candle's close, else 0\n",
    "train_data['target'] = (train_data['close'].shift(-1) > train_data['close']).astype(int)\n",
    "test_data['target']  = (test_data['close'].shift(-1)  > test_data['close']).astype(int)\n",
    "\n",
    "# Choose technical indicator signals as features\n",
    "features = ['200_EMA_signal', 'vwap_signal', 'cci_signal', 'ema_crossover']\n",
    "\n",
    "# Drop rows with NaN values (e.g. at the end of each symbol's data) for training\n",
    "train_ml = train_data.dropna(subset=features + ['target']).copy()\n",
    "test_ml  = test_data.dropna(subset=features + ['target']).copy()\n",
    "\n",
    "X_train = train_ml[features]\n",
    "y_train = train_ml['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy: 0.5300740615345549\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# 4. Train a Machine Learning Classifier\n",
    "# ---------------------------------------------------\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"\\nTraining Accuracy:\", accuracy_score(y_train, clf.predict(X_train)))\n",
    "\n",
    "# Predict probabilities on test set\n",
    "X_test = test_ml[features]\n",
    "test_ml['predicted_prob'] = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Create a predicted signal:\n",
    "# Here we define thresholds: if probability > 0.55, signal = 1 (buy); if < 0.45, signal = -1 (sell); otherwise, 0 (no trade)\n",
    "def get_signal(p):\n",
    "    if p > 0.55:\n",
    "        return 1\n",
    "    elif p < 0.45:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "test_ml['predicted_signal'] = test_ml['predicted_prob'].apply(get_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 7, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "Best Cross-Validation Accuracy: 0.5323864742477463\n",
      "Training Accuracy: 0.5330263659063016\n",
      "Test Accuracy: 0.5258027953192816\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming that the data has already been loaded, indicators computed, and split into train_data and test_data,\n",
    "# and that 'target' has been created as:\n",
    "# target = 1 if next candle's close > current candle's close, else 0.\n",
    "# Also assuming that the indicator signals are stored in:\n",
    "# ['200_EMA_signal', 'vwap_signal', 'cci_signal', 'ema_crossover']\n",
    "\n",
    "# Drop NaNs that might occur due to indicator calculation or shifting target values.\n",
    "train_ml = train_data.dropna(subset=['200_EMA_signal', 'vwap_signal', 'cci_signal', 'ema_crossover', 'target']).copy()\n",
    "test_ml  = test_data.dropna(subset=['200_EMA_signal', 'vwap_signal', 'cci_signal', 'ema_crossover', 'target']).copy()\n",
    "\n",
    "# Define the feature set and target variable.\n",
    "features = ['200_EMA_signal', 'vwap_signal', 'cci_signal', 'ema_crossover']\n",
    "X_train = train_ml[features]\n",
    "y_train = train_ml['target']\n",
    "X_test = test_ml[features]\n",
    "y_test = test_ml['target']\n",
    "\n",
    "# Set up a grid of parameters to search over.\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [3, 5, 7, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Initialize RandomForestClassifier and perform grid search with 5-fold cross validation.\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "clf_rf = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "# Print out the best parameters and cross-validation score.\n",
    "print(\"Best Parameters:\", clf_rf.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", clf_rf.best_score_)\n",
    "\n",
    "# Evaluate on the training and test sets.\n",
    "train_pred = clf_rf.predict(X_train)\n",
    "test_pred = clf_rf.predict(X_test)\n",
    "\n",
    "print(\"Training Accuracy:\", accuracy_score(y_train, train_pred))\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 59\u001b[0m\n\u001b[0;32m     57\u001b[0m rf_ext \u001b[38;5;241m=\u001b[39m RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     58\u001b[0m clf_rf_ext \u001b[38;5;241m=\u001b[39m GridSearchCV(rf_ext, param_grid_ext, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 59\u001b[0m \u001b[43mclf_rf_ext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_ext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_ext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtended Best Parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, clf_rf_ext\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtended Best Cross-Validation Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, clf_rf_ext\u001b[38;5;241m.\u001b[39mbest_score_)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    962\u001b[0m         )\n\u001b[0;32m    963\u001b[0m     )\n\u001b[1;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ----------------------------\n",
    "# Assume train_data and test_data have been computed\n",
    "# and include the following columns:\n",
    "#   - '200_EMA_signal', 'vwap_signal', 'cci_signal', 'ema_crossover'\n",
    "#   - 'CCI', '200_EMA', '9_EMA', '26_EMA', 'close', 'volume'\n",
    "#   - 'target' : 1 if next candle's close > current candle's close, else 0\n",
    "# ----------------------------\n",
    "\n",
    "# Drop rows with NaNs for the columns we'll use.\n",
    "required_cols = ['200_EMA_signal', 'vwap_signal', 'cci_signal', 'ema_crossover', \n",
    "                 'CCI', '200_EMA', '9_EMA', '26_EMA', 'close', 'volume', 'target']\n",
    "\n",
    "train_ml_ext = train_data.dropna(subset=required_cols).copy()\n",
    "test_ml_ext  = test_data.dropna(subset=required_cols).copy()\n",
    "\n",
    "# ----------------------------\n",
    "# Create additional features\n",
    "# ----------------------------\n",
    "# 1. Difference between the close and the 200 EMA.\n",
    "train_ml_ext['close_200ema_diff'] = train_ml_ext['close'] - train_ml_ext['200_EMA']\n",
    "test_ml_ext['close_200ema_diff']  = test_ml_ext['close'] - test_ml_ext['200_EMA']\n",
    "\n",
    "# 2. Difference between 9 EMA and 26 EMA.\n",
    "train_ml_ext['ema_diff'] = train_ml_ext['9_EMA'] - train_ml_ext['26_EMA']\n",
    "test_ml_ext['ema_diff']  = test_ml_ext['9_EMA'] - test_ml_ext['26_EMA']\n",
    "\n",
    "# 3. Percentage change in volume.\n",
    "train_ml_ext['vol_change'] = train_ml_ext['volume'].pct_change().fillna(0)\n",
    "test_ml_ext['vol_change']  = test_ml_ext['volume'].pct_change().fillna(0)\n",
    "\n",
    "# ----------------------------\n",
    "# Define the extended feature set.\n",
    "# ----------------------------\n",
    "features_ext = ['200_EMA_signal', 'vwap_signal', 'cci_signal', 'ema_crossover', \n",
    "                'close_200ema_diff', 'ema_diff', 'CCI', 'vol_change']\n",
    "\n",
    "X_train_ext = train_ml_ext[features_ext]\n",
    "y_train_ext = train_ml_ext['target']\n",
    "X_test_ext  = test_ml_ext[features_ext]\n",
    "y_test_ext  = test_ml_ext['target']\n",
    "\n",
    "# ----------------------------\n",
    "# Grid search with RandomForest using the extended feature set\n",
    "# ----------------------------\n",
    "param_grid_ext = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [5, 7, 10, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "rf_ext = RandomForestClassifier(random_state=42)\n",
    "clf_rf_ext = GridSearchCV(rf_ext, param_grid_ext, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "clf_rf_ext.fit(X_train_ext, y_train_ext)\n",
    "\n",
    "print(\"Extended Best Parameters:\", clf_rf_ext.best_params_)\n",
    "print(\"Extended Best Cross-Validation Accuracy:\", clf_rf_ext.best_score_)\n",
    "\n",
    "train_pred_ext = clf_rf_ext.predict(X_train_ext)\n",
    "test_pred_ext  = clf_rf_ext.predict(X_test_ext)\n",
    "\n",
    "print(\"Extended Training Accuracy:\", accuracy_score(y_train_ext, train_pred_ext))\n",
    "print(\"Extended Test Accuracy:\", accuracy_score(y_test_ext, test_pred_ext))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL: Number of trades = 50, Avg profit = 0.1132, Win rate = 34.0%\n",
      "ABT: Number of trades = 30, Avg profit = -0.3237, Win rate = 23.3%\n",
      "ACN: Number of trades = 25, Avg profit = -0.1222, Win rate = 32.0%\n",
      "ADBE: Number of trades = 35, Avg profit = -0.2689, Win rate = 31.4%\n",
      "ADP: Number of trades = 18, Avg profit = 0.5552, Win rate = 38.9%\n",
      "AMZN: Number of trades = 51, Avg profit = -0.0841, Win rate = 31.4%\n",
      "AVGO: Number of trades = 125, Avg profit = 0.1696, Win rate = 35.2%\n",
      "BAC: Number of trades = 31, Avg profit = -0.0856, Win rate = 25.8%\n",
      "CMCSA: Number of trades = 39, Avg profit = -0.0113, Win rate = 33.3%\n",
      "COST: Number of trades = 27, Avg profit = -1.8685, Win rate = 25.9%\n",
      "CRM: Number of trades = 46, Avg profit = 1.0225, Win rate = 43.5%\n",
      "CVX: Number of trades = 31, Avg profit = -0.4287, Win rate = 22.6%\n",
      "DHR: Number of trades = 43, Avg profit = 0.2411, Win rate = 37.2%\n",
      "DIA: Number of trades = 14, Avg profit = -1.0299, Win rate = 28.6%\n",
      "DIS: Number of trades = 34, Avg profit = -0.0091, Win rate = 32.4%\n",
      "GOOGL: Number of trades = 53, Avg profit = 0.0694, Win rate = 34.0%\n",
      "HD: Number of trades = 32, Avg profit = -0.1074, Win rate = 31.2%\n",
      "HON: Number of trades = 41, Avg profit = 0.4564, Win rate = 39.0%\n",
      "IBM: Number of trades = 38, Avg profit = -0.2370, Win rate = 31.6%\n",
      "IDU: Number of trades = 17, Avg profit = -0.2211, Win rate = 29.4%\n",
      "INTC: Number of trades = 111, Avg profit = -0.0015, Win rate = 33.3%\n",
      "IWM: Number of trades = 19, Avg profit = 0.1137, Win rate = 36.8%\n",
      "IYT: Number of trades = 24, Avg profit = -0.1973, Win rate = 25.0%\n",
      "JNJ: Number of trades = 19, Avg profit = -0.6813, Win rate = 21.1%\n",
      "JPM: Number of trades = 29, Avg profit = -0.8934, Win rate = 20.7%\n",
      "KO: Number of trades = 26, Avg profit = -0.1643, Win rate = 26.9%\n",
      "LLY: Number of trades = 45, Avg profit = -0.9844, Win rate = 28.9%\n",
      "MA: Number of trades = 22, Avg profit = -0.7462, Win rate = 27.3%\n",
      "MCD: Number of trades = 18, Avg profit = 0.1469, Win rate = 33.3%\n",
      "MDLZ: Number of trades = 36, Avg profit = -0.0896, Win rate = 27.8%\n",
      "MDT: Number of trades = 29, Avg profit = -0.3149, Win rate = 20.7%\n",
      "META: Number of trades = 68, Avg profit = -0.5103, Win rate = 30.9%\n",
      "MRK: Number of trades = 36, Avg profit = 0.0969, Win rate = 36.1%\n",
      "MSFT: Number of trades = 33, Avg profit = -0.7072, Win rate = 27.3%\n",
      "NFLX: Number of trades = 41, Avg profit = -0.4028, Win rate = 31.7%\n",
      "NKE: Number of trades = 49, Avg profit = 0.1139, Win rate = 38.8%\n",
      "NVDA: Number of trades = 126, Avg profit = 0.0041, Win rate = 33.3%\n",
      "ORCL: Number of trades = 75, Avg profit = -0.0979, Win rate = 30.7%\n",
      "PFE: Number of trades = 30, Avg profit = 0.0376, Win rate = 40.0%\n",
      "PG: Number of trades = 20, Avg profit = -0.0555, Win rate = 35.0%\n",
      "PYPL: Number of trades = 52, Avg profit = 0.0675, Win rate = 36.5%\n",
      "QCOM: Number of trades = 64, Avg profit = -0.4456, Win rate = 25.0%\n",
      "QQQ: Number of trades = 28, Avg profit = -1.0947, Win rate = 25.0%\n",
      "SPGI: Number of trades = 22, Avg profit = -0.6822, Win rate = 27.3%\n",
      "SPY: Number of trades = 14, Avg profit = -0.4058, Win rate = 28.6%\n",
      "T: Number of trades = 33, Avg profit = -0.0178, Win rate = 30.3%\n",
      "TMO: Number of trades = 33, Avg profit = 1.7600, Win rate = 42.4%\n",
      "TSLA: Number of trades = 164, Avg profit = 0.5200, Win rate = 37.2%\n",
      "TXN: Number of trades = 53, Avg profit = -0.2734, Win rate = 28.3%\n",
      "UNH: Number of trades = 41, Avg profit = -0.0757, Win rate = 34.1%\n",
      "UPS: Number of trades = 34, Avg profit = -0.3022, Win rate = 26.5%\n",
      "V: Number of trades = 22, Avg profit = -0.9243, Win rate = 22.7%\n",
      "VTI: Number of trades = 17, Avg profit = -0.7045, Win rate = 23.5%\n",
      "VXX: Number of trades = 112, Avg profit = 0.0644, Win rate = 37.5%\n",
      "VZ: Number of trades = 19, Avg profit = -0.1905, Win rate = 15.8%\n",
      "WMT: Number of trades = 22, Avg profit = -0.3751, Win rate = 22.7%\n",
      "XOM: Number of trades = 38, Avg profit = -0.2834, Win rate = 23.7%\n",
      "\n",
      "Overall: Total profit = -205.3432, Overall win rate = 31.9%\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# 5. Trade Simulation on Test Set Using ML-Based Signals\n",
    "# ---------------------------------------------------\n",
    "def simulate_trade(df, start_index, signal, risk_pct=0.01):\n",
    "    \"\"\"\n",
    "    Simulate a trade for a given symbol's DataFrame (sorted by timestamp) using the ML signal.\n",
    "    The trade uses the next candle's open as entry, with a profit target of 2×risk and stop loss of 1×risk.\n",
    "    \"\"\"\n",
    "    if start_index + 1 >= len(df):\n",
    "        return None, len(df)\n",
    "    \n",
    "    entry = df.iloc[start_index + 1][\"open\"]\n",
    "    risk = risk_pct * entry\n",
    "    profit_target = 2 * risk  # 2:1 reward to risk\n",
    "\n",
    "    exit_price = None\n",
    "    exit_index = None\n",
    "\n",
    "    for i in range(start_index + 1, len(df)):\n",
    "        row = df.iloc[i]\n",
    "        if signal == 1:  # Long trade\n",
    "            if row[\"high\"] >= entry + profit_target:  # Profit target reached\n",
    "                exit_price = entry + profit_target\n",
    "                exit_index = i\n",
    "                break\n",
    "            if row[\"low\"] <= entry - risk:  # Stop loss reached\n",
    "                exit_price = entry - risk\n",
    "                exit_index = i\n",
    "                break\n",
    "        elif signal == -1:  # Short trade\n",
    "            if row[\"low\"] <= entry - profit_target:  # Profit target reached for short\n",
    "                exit_price = entry - profit_target\n",
    "                exit_index = i\n",
    "                break\n",
    "            if row[\"high\"] >= entry + risk:  # Stop loss reached for short\n",
    "                exit_price = entry + risk\n",
    "                exit_index = i\n",
    "                break\n",
    "\n",
    "    if exit_price is None:\n",
    "        exit_price = df.iloc[-1][\"close\"]\n",
    "        exit_index = len(df) - 1\n",
    "\n",
    "    if signal == 1:\n",
    "        profit = exit_price - entry\n",
    "    else:\n",
    "        profit = entry - exit_price\n",
    "\n",
    "    return profit, exit_index\n",
    "\n",
    "# Run trade simulation for each symbol in the test set based on ML predictions\n",
    "trade_results_ml = {}\n",
    "risk_pct = 0.01  # Risk percentage\n",
    "\n",
    "# Process each symbol separately\n",
    "for symbol in test_ml[\"symbol\"].unique():\n",
    "    symbol_df = test_ml[test_ml[\"symbol\"] == symbol].sort_values(\"timestamp\").reset_index(drop=True)\n",
    "    trades = []\n",
    "    i = 0\n",
    "    while i < len(symbol_df):\n",
    "        if symbol_df.loc[i, \"predicted_signal\"] != 0:\n",
    "            signal = symbol_df.loc[i, \"predicted_signal\"]\n",
    "            trade_profit, exit_idx = simulate_trade(symbol_df, i, signal, risk_pct=risk_pct)\n",
    "            if trade_profit is not None:\n",
    "                trades.append(trade_profit)\n",
    "                # Jump to the candle after the trade exit to avoid overlapping trades\n",
    "                i = exit_idx + 1\n",
    "                continue\n",
    "        i += 1\n",
    "    trade_results_ml[symbol] = trades\n",
    "    if trades:\n",
    "        avg_profit = np.mean(trades)\n",
    "        win_rate = np.mean([1 if p > 0 else 0 for p in trades])\n",
    "        print(f\"{symbol}: Number of trades = {len(trades)}, Avg profit = {avg_profit:.4f}, Win rate = {win_rate:.1%}\")\n",
    "    else:\n",
    "        print(f\"{symbol}: No trades executed\")\n",
    "\n",
    "# Overall performance across symbols\n",
    "all_trades_ml = [p for trades in trade_results_ml.values() for p in trades]\n",
    "if all_trades_ml:\n",
    "    overall_profit_ml = np.sum(all_trades_ml)\n",
    "    overall_win_rate_ml = np.mean([1 if p > 0 else 0 for p in all_trades_ml])\n",
    "    print(f\"\\nOverall: Total profit = {overall_profit_ml:.4f}, Overall win rate = {overall_win_rate_ml:.1%}\")\n",
    "else:\n",
    "    print(\"No trades executed overall.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
